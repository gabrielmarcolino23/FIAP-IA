{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FarmTech Solutions - An√°lise de Rendimento de Safras\n",
    "\n",
    "**Autor:** [SEU_NOME_AQUI]  \n",
    "**RM:** [SEU_RM_AQUI]  \n",
    "**Projeto:** Fase 5 - Machine Learning e Computa√ß√£o em Nuvem  \n",
    "**Data:** Setembro 2024\n",
    "\n",
    "## Descri√ß√£o do Projeto\n",
    "\n",
    "Este projeto analisa dados de condi√ß√µes de solo e temperatura relacionados com diferentes tipos de culturas agr√≠colas para prever o rendimento de safras. Utilizamos t√©cnicas de Machine Learning supervisionado e n√£o supervisionado para identificar padr√µes e criar modelos preditivos.\n",
    "\n",
    "### Objetivos:\n",
    "1. **An√°lise Explorat√≥ria:** Familiariza√ß√£o com os dados e identifica√ß√£o de padr√µes\n",
    "2. **Clusteriza√ß√£o:** Identifica√ß√£o de tend√™ncias e cen√°rios discrepantes (outliers)\n",
    "3. **Modelagem Preditiva:** Desenvolvimento de 5 modelos diferentes para predi√ß√£o de rendimento\n",
    "4. **Avalia√ß√£o:** Compara√ß√£o dos modelos usando m√©tricas apropriadas\n",
    "\n",
    "### Dataset:\n",
    "- **Fonte:** crop_yield.csv\n",
    "- **Registros:** 157 observa√ß√µes\n",
    "- **Culturas:** Cocoa beans, Oil palm fruit, Rice paddy, Rubber natural\n",
    "- **Vari√°veis independentes:** Precipita√ß√£o, Umidade espec√≠fica, Umidade relativa, Temperatura\n",
    "- **Vari√°vel dependente:** Rendimento (toneladas por hectare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importa√ß√£o de Bibliotecas e Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('crop_yield.csv')\n",
    "\n",
    "print(\"üìä Dataset carregado com sucesso!\")\n",
    "print(f\"Dimens√µes: {df.shape}\")\n",
    "print(f\"\\nPrimeiras 5 linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An√°lise Explorat√≥ria de Dados\n",
    "\n",
    "Nesta se√ß√£o, vamos explorar o dataset para entender a distribui√ß√£o dos dados, identificar padr√µes e rela√ß√µes entre as vari√°veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã Informa√ß√µes Gerais do Dataset:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"N√∫mero de registros: {len(df)}\")\n",
    "print(f\"N√∫mero de colunas: {len(df.columns)}\")\n",
    "print(f\"\\nTipos de dados:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nValores ausentes:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nCulturas presentes:\")\n",
    "print(df['Crop'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Estat√≠sticas Descritivas:\")\n",
    "print(\"=\" * 50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Distribui√ß√£o das Vari√°veis Num√©ricas', fontsize=16, fontweight='bold')\n",
    "\n",
    "numerical_cols = ['Precipitation (mm day-1)', 'Specific Humidity at 2 Meters (g/kg)', \n",
    "                  'Relative Humidity at 2 Meters (%)', 'Temperature at 2 Meters (C)', 'Yield']\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    row = i // 3\n",
    "    col_idx = i % 3\n",
    "    \n",
    "    axes[row, col_idx].hist(df[col], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[row, col_idx].set_title(f'Distribui√ß√£o: {col}', fontweight='bold')\n",
    "    axes[row, col_idx].set_xlabel(col)\n",
    "    axes[row, col_idx].set_ylabel('Frequ√™ncia')\n",
    "    axes[row, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, crop in enumerate(df['Crop'].unique()):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    crop_data = df[df['Crop'] == crop]\n",
    "    plt.scatter(crop_data['Temperature at 2 Meters (C)'], crop_data['Yield'], \n",
    "               alpha=0.7, s=60)\n",
    "    plt.title(f'{crop}\\nTemperatura vs Rendimento', fontweight='bold')\n",
    "    plt.xlabel('Temperatura (¬∞C)')\n",
    "    plt.ylabel('Rendimento (t/ha)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.boxplot(data=df, x='Crop', y='Yield')\n",
    "plt.title('Distribui√ß√£o do Rendimento por Cultura', fontweight='bold')\n",
    "plt.xlabel('Cultura')\n",
    "plt.ylabel('Rendimento (t/ha)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Matriz de Correla√ß√£o das Vari√°veis Num√©ricas', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç Principais correla√ß√µes com o Rendimento:\")\n",
    "yield_correlations = correlation_matrix['Yield'].sort_values(key=abs, ascending=False)\n",
    "for var, corr in yield_correlations.items():\n",
    "    if var != 'Yield':\n",
    "        print(f\"  {var}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principais Insights da An√°lise Explorat√≥ria:\n",
    "\n",
    "1. **Distribui√ß√£o dos dados:** [Descreva aqui as principais observa√ß√µes sobre as distribui√ß√µes]\n",
    "2. **Correla√ß√µes:** [Destaque as correla√ß√µes mais significativas encontradas]\n",
    "3. **Diferen√ßas entre culturas:** [Comente sobre as diferen√ßas de rendimento entre as culturas]\n",
    "4. **Qualidade dos dados:** [Avalie a presen√ßa de outliers, valores ausentes, etc.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning N√£o Supervisionado\n",
    "\n",
    "Utilizaremos t√©cnicas de clusteriza√ß√£o para identificar padr√µes nos dados e detec√ß√£o de outliers para encontrar cen√°rios discrepantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_clustering = ['Precipitation (mm day-1)', 'Specific Humidity at 2 Meters (g/kg)', \n",
    "                          'Relative Humidity at 2 Meters (%)', 'Temperature at 2 Meters (C)']\n",
    "\n",
    "X_cluster = df[features_for_clustering]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "print(\"‚úÖ Dados preparados para clusteriza√ß√£o (normalizados)\")\n",
    "print(f\"Shape dos dados: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.title('M√©todo do Cotovelo para Determina√ß√£o do N√∫mero √ìtimo de Clusters', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('N√∫mero de Clusters (k)')\n",
    "plt.ylabel('In√©rcia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "optimal_k = 4\n",
    "print(f\"üéØ N√∫mero √≥timo de clusters escolhido: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "print(f\"üìä Distribui√ß√£o dos clusters:\")\n",
    "print(df['Cluster'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nüåæ Distribui√ß√£o das culturas por cluster:\")\n",
    "cluster_crop_distribution = pd.crosstab(df['Cluster'], df['Crop'])\n",
    "print(cluster_crop_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Visualiza√ß√£o dos Clusters', fontsize=16, fontweight='bold')\n",
    "\n",
    "feature_pairs = [('Precipitation (mm day-1)', 'Temperature at 2 Meters (C)'),\n",
    "                ('Specific Humidity at 2 Meters (g/kg)', 'Relative Humidity at 2 Meters (%)'),\n",
    "                ('Temperature at 2 Meters (C)', 'Yield'),\n",
    "                ('Precipitation (mm day-1)', 'Yield')]\n",
    "\n",
    "for i, (x_var, y_var) in enumerate(feature_pairs):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    scatter = axes[row, col].scatter(df[x_var], df[y_var], c=df['Cluster'], \n",
    "                                    cmap='viridis', alpha=0.7, s=60)\n",
    "    axes[row, col].set_xlabel(x_var)\n",
    "    axes[row, col].set_ylabel(y_var)\n",
    "    axes[row, col].set_title(f'{x_var} vs {y_var}', fontweight='bold')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.colorbar(scatter, ax=axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "outliers = isolation_forest.fit_predict(X_scaled)\n",
    "\n",
    "df['Outlier'] = outliers\n",
    "df['Is_Outlier'] = df['Outlier'] == -1\n",
    "\n",
    "outlier_count = sum(df['Is_Outlier'])\n",
    "print(f\"üö® Outliers detectados: {outlier_count} ({outlier_count/len(df)*100:.1f}% dos dados)\")\n",
    "\n",
    "print(f\"\\nüìã Distribui√ß√£o de outliers por cultura:\")\n",
    "outlier_by_crop = df.groupby('Crop')['Is_Outlier'].sum()\n",
    "for crop, count in outlier_by_crop.items():\n",
    "    total_crop = len(df[df['Crop'] == crop])\n",
    "    percentage = count/total_crop*100\n",
    "    print(f\"  {crop}: {count}/{total_crop} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Detec√ß√£o de Outliers', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, (x_var, y_var) in enumerate(feature_pairs):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    normal_data = df[df['Is_Outlier'] == False]\n",
    "    outlier_data = df[df['Is_Outlier'] == True]\n",
    "    \n",
    "    axes[row, col].scatter(normal_data[x_var], normal_data[y_var], \n",
    "                          c='blue', alpha=0.6, s=60, label='Normal')\n",
    "    axes[row, col].scatter(outlier_data[x_var], outlier_data[y_var], \n",
    "                          c='red', alpha=0.8, s=100, marker='x', label='Outlier')\n",
    "    \n",
    "    axes[row, col].set_xlabel(x_var)\n",
    "    axes[row, col].set_ylabel(y_var)\n",
    "    axes[row, col].set_title(f'{x_var} vs {y_var}', fontweight='bold')\n",
    "    axes[row, col].legend()\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lise dos Resultados de Clusteriza√ß√£o:\n",
    "\n",
    "1. **Clusters identificados:** [Descreva os padr√µes encontrados em cada cluster]\n",
    "2. **Outliers detectados:** [Analise os outliers encontrados e suas poss√≠veis causas]\n",
    "3. **Rela√ß√£o com as culturas:** [Comente sobre como as culturas se distribuem nos clusters]\n",
    "4. **Insights para agricultura:** [Explique como esses padr√µes podem ajudar na agricultura]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Supervisionado\n",
    "\n",
    "Agora vamos desenvolver modelos preditivos para prever o rendimento das safras com base nas condi√ß√µes ambientais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['Crop_Encoded'] = label_encoder.fit_transform(df['Crop'])\n",
    "\n",
    "features = ['Precipitation (mm day-1)', 'Specific Humidity at 2 Meters (g/kg)', \n",
    "           'Relative Humidity at 2 Meters (%)', 'Temperature at 2 Meters (C)', 'Crop_Encoded']\n",
    "target = 'Yield'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_ml = StandardScaler()\n",
    "X_train_scaled = scaler_ml.fit_transform(X_train)\n",
    "X_test_scaled = scaler_ml.transform(X_test)\n",
    "\n",
    "print(f\"‚úÖ Dados preparados para modelagem\")\n",
    "print(f\"Features utilizadas: {features}\")\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")\n",
    "print(f\"\\nMapeamento das culturas:\")\n",
    "for i, crop in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {i}: {crop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Support Vector Regression': SVR(kernel='rbf'),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'Neural Network': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"ü§ñ Treinando modelos...\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Treinando {name}...\")\n",
    "    \n",
    "    if name in ['Support Vector Regression', 'Neural Network']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        X_cv = X_train_scaled\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        X_cv = X_train\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X_cv, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R¬≤': r2,\n",
    "        'CV_R¬≤_Mean': cv_scores.mean(),\n",
    "        'CV_R¬≤_Std': cv_scores.std(),\n",
    "        'Predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úÖ {name} - R¬≤: {r2:.3f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "print(\"\\nüéØ Treinamento conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(3)\n",
    "\n",
    "print(\"üìä Compara√ß√£o dos Modelos:\")\n",
    "print(\"=\" * 80)\n",
    "display_cols = ['MAE', 'RMSE', 'R¬≤', 'CV_R¬≤_Mean', 'CV_R¬≤_Std']\n",
    "print(results_df[display_cols].to_string())\n",
    "\n",
    "best_model = results_df['R¬≤'].idxmax()\n",
    "print(f\"\\nüèÜ Melhor modelo: {best_model} (R¬≤ = {results_df.loc[best_model, 'R¬≤']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Predi√ß√µes vs Valores Reais por Modelo', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, (name, result) in enumerate(results.items()):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    \n",
    "    axes[row, col].scatter(y_test, result['Predictions'], alpha=0.7, s=60)\n",
    "    axes[row, col].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                       'r--', linewidth=2)\n",
    "    axes[row, col].set_xlabel('Valores Reais')\n",
    "    axes[row, col].set_ylabel('Predi√ß√µes')\n",
    "    axes[row, col].set_title(f'{name}\\nR¬≤ = {result[\"R¬≤\"]:.3f}', fontweight='bold')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['MAE', 'RMSE', 'R¬≤']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    model_names = list(results.keys())\n",
    "    values = [results[model][metric] for model in model_names]\n",
    "    \n",
    "    bars = axes[i].bar(model_names, values, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Compara√ß√£o: {metric}', fontweight='bold')\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, value in zip(bars, values):\n",
    "        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.suptitle('M√©tricas de Avalia√ß√£o dos Modelos', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df['R¬≤'].idxmax()\n",
    "best_model_obj = models[best_model_name]\n",
    "\n",
    "if best_model_name == 'Random Forest':\n",
    "    feature_importance = best_model_obj.feature_importances_\n",
    "    feature_names = features\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(importance_df['Feature'], importance_df['Importance'], \n",
    "                   alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "    plt.title(f'Import√¢ncia das Features - {best_model_name}', fontweight='bold')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Import√¢ncia')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, value in zip(bars, importance_df['Importance']):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üîç Ranking de Import√¢ncia das Features:\")\n",
    "    for i, row in importance_df.iterrows():\n",
    "        print(f\"  {row['Feature']}: {row['Importance']:.3f}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è An√°lise de import√¢ncia das features n√£o dispon√≠vel para {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lise e Conclus√µes\n",
    "\n",
    "### Principais Resultados:\n",
    "\n",
    "1. **Melhor Modelo:** [Descreva qual foi o melhor modelo e por qu√™]\n",
    "2. **Performance:** [Analise as m√©tricas obtidas]\n",
    "3. **Features mais importantes:** [Comente sobre quais vari√°veis s√£o mais relevantes]\n",
    "4. **Limita√ß√µes:** [Discuta as limita√ß√µes do estudo]\n",
    "\n",
    "### Pontos Fortes do Trabalho:\n",
    "- An√°lise explorat√≥ria completa dos dados\n",
    "- Aplica√ß√£o de t√©cnicas de clusteriza√ß√£o para identificar padr√µes\n",
    "- Detec√ß√£o e an√°lise de outliers\n",
    "- Compara√ß√£o de m√∫ltiplos algoritmos de Machine Learning\n",
    "- Valida√ß√£o cruzada para robustez dos resultados\n",
    "- Visualiza√ß√µes claras e informativas\n",
    "\n",
    "### Limita√ß√µes e Melhorias Futuras:\n",
    "- Dataset relativamente pequeno (157 registros)\n",
    "- Possibilidade de incluir mais vari√°veis ambientais\n",
    "- Teste de t√©cnicas de feature engineering\n",
    "- Implementa√ß√£o de ensemble methods\n",
    "- Coleta de dados temporais para an√°lise de s√©ries temporais\n",
    "\n",
    "### Aplica√ß√µes Pr√°ticas:\n",
    "O modelo desenvolvido pode ser utilizado pela FarmTech Solutions para:\n",
    "- Predi√ß√£o de rendimento de safras\n",
    "- Otimiza√ß√£o de condi√ß√µes de cultivo\n",
    "- Planejamento agr√≠cola\n",
    "- Detec√ß√£o de condi√ß√µes an√¥malas\n",
    "- Suporte √† tomada de decis√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ RESUMO FINAL DOS RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Dataset: {len(df)} registros, {len(df.columns)} vari√°veis\")\n",
    "print(f\"üåæ Culturas analisadas: {len(df['Crop'].unique())}\")\n",
    "print(f\"üîç Clusters identificados: {optimal_k}\")\n",
    "print(f\"üö® Outliers detectados: {outlier_count} ({outlier_count/len(df)*100:.1f}%)\")\n",
    "print(f\"üèÜ Melhor modelo: {best_model_name}\")\n",
    "print(f\"üìà Melhor R¬≤: {results_df.loc[best_model_name, 'R¬≤']:.3f}\")\n",
    "print(f\"üìâ Melhor RMSE: {results_df.loc[best_model_name, 'RMSE']:.2f}\")\n",
    "print(\"\\n‚úÖ An√°lise conclu√≠da com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}